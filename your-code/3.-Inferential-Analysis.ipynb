{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential statistics\n",
    "## Part III - Inferential Analysis\n",
    "\n",
    "We're now going to look for answers to the ongoing basketball discussions between you and your family. The main ones we want to reasearch are the following:\n",
    "\n",
    "- Your grandmother says that your sister couldn't play in a professional basketball league (not only the WNBA, but ANY professional basketball league) because she's too skinny and lacks muscle.\n",
    "- Your sister says that most female professional players fail their free throws.\n",
    "- Your brother-in-law heard on the TV that the average assists among NBA (male) and WNBA (female) players is 52 for the 2016-2017 season. He is convinced this average would be higher if we only considered the players from the WNBA.\n",
    "\n",
    "Let's investigate these claims and see if we can find proof to refute or support them.\n",
    "\n",
    "### Libraries\n",
    "Import the necessary libraries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "Load the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Birth_Place</th>\n",
       "      <th>Birthdate</th>\n",
       "      <th>Age</th>\n",
       "      <th>College</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Games Played</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>3PM</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>OREB</th>\n",
       "      <th>DREB</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TO</th>\n",
       "      <th>PTS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aerial Powers</td>\n",
       "      <td>DAL</td>\n",
       "      <td>F</td>\n",
       "      <td>183</td>\n",
       "      <td>71</td>\n",
       "      <td>21.200991</td>\n",
       "      <td>US</td>\n",
       "      <td>January 17, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Michigan State</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "      <td>30</td>\n",
       "      <td>85</td>\n",
       "      <td>35.3</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>37.5</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>80.8</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alana Beard</td>\n",
       "      <td>LA</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>73</td>\n",
       "      <td>21.329438</td>\n",
       "      <td>US</td>\n",
       "      <td>May 14, 1982</td>\n",
       "      <td>35</td>\n",
       "      <td>Duke</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>947</td>\n",
       "      <td>90</td>\n",
       "      <td>177</td>\n",
       "      <td>50.8</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>78.0</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>101</td>\n",
       "      <td>72</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex Bentley</td>\n",
       "      <td>CON</td>\n",
       "      <td>G</td>\n",
       "      <td>170</td>\n",
       "      <td>69</td>\n",
       "      <td>23.875433</td>\n",
       "      <td>US</td>\n",
       "      <td>October 27, 1990</td>\n",
       "      <td>26</td>\n",
       "      <td>Penn State</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>617</td>\n",
       "      <td>82</td>\n",
       "      <td>218</td>\n",
       "      <td>37.6</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>29.7</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>83.3</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>78</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex Montgomery</td>\n",
       "      <td>SAN</td>\n",
       "      <td>G/F</td>\n",
       "      <td>185</td>\n",
       "      <td>84</td>\n",
       "      <td>24.543462</td>\n",
       "      <td>US</td>\n",
       "      <td>December 11, 1988</td>\n",
       "      <td>28</td>\n",
       "      <td>Georgia Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>721</td>\n",
       "      <td>75</td>\n",
       "      <td>195</td>\n",
       "      <td>38.5</td>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>30.9</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>81.0</td>\n",
       "      <td>35</td>\n",
       "      <td>134</td>\n",
       "      <td>169</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alexis Jones</td>\n",
       "      <td>MIN</td>\n",
       "      <td>G</td>\n",
       "      <td>175</td>\n",
       "      <td>78</td>\n",
       "      <td>25.469388</td>\n",
       "      <td>US</td>\n",
       "      <td>August 5, 1994</td>\n",
       "      <td>23</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>R</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Team  Pos  Height  Weight        BMI Birth_Place  \\\n",
       "0    Aerial Powers  DAL    F     183      71  21.200991          US   \n",
       "1      Alana Beard   LA  G/F     185      73  21.329438          US   \n",
       "2     Alex Bentley  CON    G     170      69  23.875433          US   \n",
       "3  Alex Montgomery  SAN  G/F     185      84  24.543462          US   \n",
       "4     Alexis Jones  MIN    G     175      78  25.469388          US   \n",
       "\n",
       "           Birthdate  Age         College Experience  Games Played  MIN  FGM  \\\n",
       "0   January 17, 1994   23  Michigan State          2             8  173   30   \n",
       "1       May 14, 1982   35            Duke         12            30  947   90   \n",
       "2   October 27, 1990   26      Penn State          4            26  617   82   \n",
       "3  December 11, 1988   28    Georgia Tech          6            31  721   75   \n",
       "4     August 5, 1994   23          Baylor          R            24  137   16   \n",
       "\n",
       "   FGA   FG%  3PM  3PA   3P%  FTM  FTA   FT%  OREB  DREB  REB  AST  STL  BLK  \\\n",
       "0   85  35.3   12   32  37.5   21   26  80.8     6    22   28   12    3    6   \n",
       "1  177  50.8    5   18  27.8   32   41  78.0    19    82  101   72   63   13   \n",
       "2  218  37.6   19   64  29.7   35   42  83.3     4    36   40   78   22    3   \n",
       "3  195  38.5   21   68  30.9   17   21  81.0    35   134  169   65   20   10   \n",
       "4   50  32.0    7   20  35.0   11   12  91.7     3     9   12   12    7    0   \n",
       "\n",
       "   TO  PTS  DD2  TD3  \n",
       "0  12   93    0    0  \n",
       "1  40  217    0    0  \n",
       "2  24  218    0    0  \n",
       "3  38  188    2    0  \n",
       "4  14   50    0    0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "wnba = pd.read_csv(\"/Users/ricardomendes/Desktop/LABS/Week5/M2-mini-project2/data/wnba_clean.csv\")\n",
    "wnba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Can my sister play in a professional female basketball league?\n",
    "\n",
    "As we said, you grandmother is convinced that your sister couldn't play in a professional league because of her physique and weight (her weight is 67kg). \n",
    "\n",
    "To find an actual answer to the question we first need to know what's the average weight of a professional female basketball player. The data we have only refers to the WNBA league and not to every female professional basketball league in the world, therefore we have no way of actually calculating it.\n",
    "\n",
    "Still, given that we do have *some* data we can **infer** it using a sample of players like the one we have. \n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the average weight. Do you feel it actually fulfills those requirements? Do you need to make any assumptions? We could calculate a confidence interval to do the inference, but do you know any other ways?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 32)\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "\n",
    "# from our plots in exploratory data analysis we saw that weight of wnba players follows a rather\n",
    "# normal distribution. therefore it would be possible to use this sample and normal distribution in\n",
    "# order to inger from the sample to the population (women basketball players)\n",
    "\n",
    "# for a more accurate outcome, we could consider removing weight outliers -> see previous step:\n",
    "\n",
    "# Checking top/bottom 5 comparing weight to height and age to birthdate:\n",
    "# 104-113 kg for 185-196 cm, 55-59 kg for 165-175 cm \n",
    "\n",
    "# Drop outliers based on weight column\n",
    "wnba = wnba[(wnba[\"Weight\"] >= 59) & (wnba[\"Weight\"] <= 104)]\n",
    "\n",
    "print(wnba.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the average weight with a confidence level of 95%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.97887323943662\n",
      "10.996110408297898\n",
      "142\n",
      "0.95\n",
      "(77.17027122332428, 80.78747525554897)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import scipy.stats as st\n",
    "\n",
    "sample_mean = wnba[\"Weight\"].mean()\n",
    "sample_std = wnba[\"Weight\"].std(ddof = 1)\n",
    "sample_n = len(wnba[\"Weight\"])\n",
    "alpha = 0.95\n",
    "\n",
    "\n",
    "ci = st.norm.interval(confidence = alpha, loc = sample_mean, scale = sample_std / np.sqrt(sample_n))\n",
    "\n",
    "print(sample_mean)\n",
    "print(sample_std)\n",
    "print(sample_n)\n",
    "print(alpha)\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you say about these results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "\"\"\"\n",
    "With 95% confidence, the mean weight of a female basketball player is between 77.1 and 80.4 kg\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If your sister weighs 67kg what would you tell your grandmother in regards to her assumption?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\n",
    "\"\"\"\n",
    "Based on the 95% confidence interval we calculated using the WNBA dataset, \n",
    "it appears that the average weight of professional female basketball players is between 75.78 and 81.91 kg.\n",
    "Since your sister's weight of 67 kg falls below this range,\n",
    "it is possible that her weight could be a disadvantage in playing professionally.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Can you plot the probability distribution of the average weight, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Do female professional basketball players fail the majority of their free throws?\n",
    "\n",
    "You do not agree with your sister when she says that most female players fail their free throws. You decide to try and estimate the percentage of players that fail more than 40% of their free throws using, you guessed it, the WNBA sample.\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to be used to infer the proportion of players that miss more than 40% of their free throws. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of players who miss more than 40% of their free throws: 0.099\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "\n",
    "\n",
    "missed_ft = wnba[wnba['FT%'] < 60] # Select players who miss more than 40% of their free throws\n",
    "prop_missed_ft = len(missed_ft) / len(wnba) # Calculate proportion of players who miss more than 40% of their free throws\n",
    "print(f\"Proportion of players who miss more than 40% of their free throws: {prop_missed_ft:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that all the requirements have been taken into account, compute the confidence interval of the proportion with a confidence level of 95%:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for proportion of players who miss more than 40% of their free throws: [0.050, 0.148]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# Calculate standard error and margin of error\n",
    "n = len(wnba)\n",
    "p = prop_missed_ft\n",
    "se = math.sqrt(p*(1-p)/n)\n",
    "z = 1.96 # z-value for 95% confidence interval\n",
    "me = z * se\n",
    "\n",
    "# Calculate confidence interval\n",
    "lower_bound = p - me\n",
    "upper_bound = p + me\n",
    "\n",
    "print(f\"95% confidence interval for proportion of players who miss more than 40% of their free throws: [{lower_bound:.3f}, {upper_bound:.3f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can you comment about our result? What would you tell your sister?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the probability distribution of the proportion of missed free throws, indicating where the critical region is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Is the average number of assists for WNBA players only higher than the average for WNBA and NBA players together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your brother-in-law is convinced that the average assists for female professional players is higher than the average of both female and male players combined (which is 52 for the 2016-2017 season). You would like to actually prove if this is true or not but you remember your stats teacher saying \"you can't *prove* anything, you just can say that *you are not* saying foolishness\".\n",
    "\n",
    "**How would you do it? Try and think about the requirements that your sample must satisfy in order to do that. Do you feel it actually fulfills those requirements? Do you need to make any assumptions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use a two-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "\n",
    "p = (wnba[\"AST\"]).count()\n",
    "\n",
    "# 1. Set the hypothesis\n",
    "# H0: mu = 52\n",
    "# H1: mu != 52\n",
    "mu = 52\n",
    "cit = \"two-sided\"\n",
    "\n",
    "# 2. Choose significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# 3. Sample\n",
    "n = 142\n",
    "sample = wnba[\"AST\"].sample(n)\n",
    "\n",
    "# 4. Compute the statistic & 5. Get p-value -> st.ttest_1samp\n",
    "t_test_result = st.ttest_1samp(sample, mu, alternative = cit)\n",
    "\n",
    "# 6. Decide\n",
    "if t_test_result.pvalue < alpha: \n",
    "    print(\"We can reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We can not reject the null hypothesis\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here\n",
    "\"\"\"\n",
    "The average number of assists for WNBA players is not 52\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now use a one-tailed one-sample t-test to see if we can reject (or not) the null hypothesis with a 95% confidence level.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can not reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "#your-answer-here\n",
    "\n",
    "p = (wnba[\"AST\"]).count()\n",
    "\n",
    "# 1. Set the hypothesis\n",
    "# H0: mu <= 52\n",
    "# H1: mu > 52\n",
    "mu = 52\n",
    "cit = \"greater\"\n",
    "\n",
    "# 2. Choose significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# 3. Sample\n",
    "n = 142\n",
    "sample = wnba[\"AST\"].sample(n)\n",
    "\n",
    "# 4. Compute the statistic & 5. Get p-value -> st.ttest_1samp\n",
    "t_test_result = st.ttest_1samp(sample, mu, alternative = cit)\n",
    "\n",
    "# 6. Decide\n",
    "if t_test_result.pvalue < alpha and t_test_result.statistic > 0:  \n",
    "    print(\"We can reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"We can not reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Can you plot the resulting t-distribution of both tests? Indicate where the is the critical region and where does your statistic fall.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Satisfying your curiosity\n",
    "\n",
    "You finally managed to solve your family's debates over basketball! While you were doing that you started to take an interest in the normal distribution.\n",
    "\n",
    "You read that the normal distribution is present in a lot of natural phenomenons, like blood pressure, IQ, weight and height. If, for example, we could plot the distribution of the weights of every human on the planet right now it would have the shape of a normal distribution.\n",
    "\n",
    "In light of this you would like to see if it's possible to check if the distribution of the weights of the WNBA players is a sample distribution that comes from a population that has a normal distribution, because theoretically this should be the case.\n",
    "\n",
    "**How would you try to demonstrate that our sample fits a normal distribution? What kind of test would you use? Would you have to make any assumptions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are your comments in regards to the results of the test?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your-answer-here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
